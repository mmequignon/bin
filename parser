#!/usr/bin/python3

import httplib2
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import re
import sys
import urllib.request

class Site:
    def __init__(self):
        self.url = self.getUrl()
        self.domain = self.getDomain()
        self.links = self.getLinks()
        self.pages = self.getPages()
        self.mp3links = self.getMp3Links()

    def getUrl(self):
        url = None
        while not url:
            url=input("URL : ")
        return url

    def getDomain( self ):
        parsed_uri = urlparse(self.url)
        return parsed_uri.netloc

    def getLinks(self):
        return Page(self.url).links

    def getPages(self):
        array=[]
        for i in self.links:
            array.append(Page(i))
        list(set(array))
        return array

    def getMp3Links(self):
        array=[]
        for i in self.pages:
            array.extend(i.mp3Links)
        list(set(array))
        return array

    def download(self):
        for i in self.mp3links:
            i.download()

class Page:
    def __init__(self, url):
        self.url = url
        self.domain = self.getDomain()
        self.domainRegex = self.getDomainRegex()
        self.content = self.getContent()
        self.links = self.getLinks()
        self.mp3Links = self.getmp3Links()

    def getDomain(self):
        parsed_uri = urlparse(self.url)
        return parsed_uri.netloc

    def getDomainRegex(self):
        return r"http(s)?\:\/\/"+self.domain+".*"

    def getContent(self):
        try :
            http = httplib2.Http()
            status, response = http.request(self.url)
            return response
        except :
            print("403 : Parsing disallowed here !")
            raise

    def getLinks(self):
        array=[]
        soup = BeautifulSoup( self.content , "html.parser")
        for link in soup.find_all("a" , href=re.compile(self.domainRegex)):
            link = link.get("href")
            if File.mp3(link) or link==self.url:
                continue
            array.append(link)
        list(set(array))
        return array

    def getmp3Links(self):
        array = []
        soup = BeautifulSoup( self.content , "html.parser")
        for link in soup.find_all("a", href=re.compile("http.*\.mp3$")):
            array.append(File(link.get("href")))
        list(set(array))
        return array

class File:
    def __init__(self, url):
        self.url = url
        self.name = self.getFileName()

    def getFileName(self):
        return self.url.split("/")[-1]

    def download(self):
        global fileName
        fileName = self.name       
        urllib.request.urlretrieve(self.url , self.name , reporthook=File.dlProgress)
    
    @staticmethod
    def dlProgress(count, blockSize, totalSize):
        percent = int(count*blockSize*100/totalSize)
        sys.stdout.write("\r" + "Downloading : " +  fileName + "...%d%%" % percent)
        sys.stdout.flush()


    @staticmethod
    def mp3(url):
        return re.match(r".*\.mp3", url )


monSite = Site()
monSite.download()

